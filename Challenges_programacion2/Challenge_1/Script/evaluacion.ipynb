{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importaci√≥n de librer√≠as\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, \n",
    "                           f1_score, roc_auc_score, confusion_matrix, roc_curve, auc)\n",
    "import mlflow\n",
    "import mlflow.sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuraci√≥n de paths\n",
    "IMAGES_PATH = r\"C:\\Users\\abrah\\Documents\\Maestr√≠a\\Segundo_semestre\\Programacion_2\\Challenge_1\\Im√°genes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Error en carga:\n",
      "Object arrays cannot be loaded when allow_pickle=False\n",
      "\n",
      "üîß Soluci√≥n posible:\n",
      "- Ejecuta primero train_model.py para generar los archivos necesarios\n",
      "- Verifica que los archivos .npy no est√©n corruptos\n"
     ]
    }
   ],
   "source": [
    "# Cargar modelo y datos\n",
    "try:\n",
    "    # Verificaci√≥n de archivos\n",
    "    REQUIRED_FILES = ['knn_model.pkl', 'scaler.pkl', 'X_test.npy', 'y_test.npy', 'feature_names.npy']\n",
    "    missing_files = [f for f in REQUIRED_FILES if not os.path.exists(os.path.join(IMAGES_PATH, f))]\n",
    "    \n",
    "    if missing_files:\n",
    "        raise FileNotFoundError(f\"Archivos faltantes:\\n- \" + \"\\n- \".join(missing_files))\n",
    "\n",
    "    # Carga de recursos\n",
    "    model = joblib.load(os.path.join(IMAGES_PATH, 'knn_model.pkl'))\n",
    "    scaler = joblib.load(os.path.join(IMAGES_PATH, 'scaler.pkl'))\n",
    "    X_test = np.load(os.path.join(IMAGES_PATH, 'X_test.npy'))\n",
    "    y_test = np.load(os.path.join(IMAGES_PATH, 'y_test.npy'))\n",
    "    feature_names = np.load(os.path.join(IMAGES_PATH, 'feature_names.npy'))\n",
    "\n",
    "    # Conversi√≥n a DataFrame con los nombres originales\n",
    "    X_test_df = pd.DataFrame(X_test, columns=feature_names)\n",
    "    \n",
    "    # Normalizaci√≥n (conservando nombres)\n",
    "    X_test_scaled = scaler.transform(X_test_df)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Error en carga:\\n{str(e)}\")\n",
    "    print(\"\\nüîß Soluci√≥n posible:\")\n",
    "    print(\"- Ejecuta primero train_model.py para generar los archivos necesarios\")\n",
    "    print(\"- Verifica que los archivos .npy no est√©n corruptos\")\n",
    "    exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Error en evaluaci√≥n:\n",
      "name 'X_test_scaled' is not defined\n"
     ]
    }
   ],
   "source": [
    "# Evaluaci√≥n del modelo\n",
    "\n",
    "try:\n",
    "    # Predicciones\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    y_probs = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    \n",
    "    # M√©tricas\n",
    "    metrics = {\n",
    "        'Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'Precision': precision_score(y_test, y_pred),\n",
    "        'Recall': recall_score(y_test, y_pred),\n",
    "        'F1-Score': f1_score(y_test, y_pred),\n",
    "        'AUC-ROC': roc_auc_score(y_test, y_probs)\n",
    "    }\n",
    "\n",
    "    # Matriz de confusi√≥n\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Curva ROC\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_probs)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Error en evaluaci√≥n:\\n{str(e)}\")\n",
    "    exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizaci√≥n y guardado\n",
    "\n",
    "def save_plots(conf_matrix, roc_data, save_path):\n",
    "    # Matriz de confusi√≥n\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(\n",
    "        conf_matrix, \n",
    "        annot=True, \n",
    "        fmt='d', \n",
    "        cmap='Blues',\n",
    "        xticklabels=['Benigno (B)', 'Maligno (M)'],\n",
    "        yticklabels=['Benigno (B)', 'Maligno (M)']\n",
    "    )\n",
    "    plt.title(\"Matriz de Confusi√≥n - KNN\")\n",
    "    plt.xlabel(\"Predicci√≥n\")\n",
    "    plt.ylabel(\"Real\")\n",
    "    plt.savefig(os.path.join(save_path, \"confusion_matrix_knn.png\"))\n",
    "    plt.close()\n",
    "    \n",
    "    # Curva ROC\n",
    "    fpr, tpr, roc_auc = roc_data\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC (AUC = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "    plt.xlabel(\"Tasa de Falsos Positivos\")\n",
    "    plt.ylabel(\"Tasa de Verdaderos Positivos\")\n",
    "    plt.title(\"Curva ROC - KNN\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig(os.path.join(save_path, \"roc_curve_knn.png\"))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Registro en MLFlow\n",
    "\n",
    "def log_to_mlflow(metrics, conf_matrix, run_name=\"KNN Evaluation\"):\n",
    "    mlflow.set_experiment(\"Breast Cancer - KNN\")\n",
    "    \n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "        # Log metrics\n",
    "        mlflow.log_metrics(metrics)\n",
    "        \n",
    "        # Log artifacts\n",
    "        mlflow.log_artifacts(IMAGES_PATH)\n",
    "        \n",
    "        # Log confusion matrix as a plot\n",
    "        mlflow.log_artifact(os.path.join(IMAGES_PATH, \"confusion_matrix_knn.png\"))\n",
    "        mlflow.log_artifact(os.path.join(IMAGES_PATH, \"roc_curve_knn.png\"))\n",
    "        \n",
    "        print(f\"Run ID: {mlflow.active_run().info.run_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Error durante la evaluaci√≥n: name 'load_and_validate_data' is not defined\n"
     ]
    }
   ],
   "source": [
    "# Ejecuci√≥n principal\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # 1. Cargar y validar datos\n",
    "        model, X_test_scaled, y_test = load_and_validate_data()\n",
    "        \n",
    "        # 2. Evaluar modelo\n",
    "        metrics, conf_matrix, roc_data = evaluate_model(model, X_test_scaled, y_test)\n",
    "        \n",
    "        # 3. Imprimir m√©tricas\n",
    "        print(\"\\nM√©tricas de Evaluaci√≥n:\")\n",
    "        for name, value in metrics.items():\n",
    "            print(f\"{name}: {value:.4f}\")\n",
    "        \n",
    "        # 4. Guardar gr√°ficos\n",
    "        save_plots(conf_matrix, roc_data, IMAGES_PATH)\n",
    "        \n",
    "        # 5. Registrar en MLFlow\n",
    "        log_to_mlflow(metrics, conf_matrix)\n",
    "        \n",
    "        print(\"\\n Evaluaci√≥n completada exitosamente.\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"\\n Error durante la evaluaci√≥n: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:programacion2]",
   "language": "python",
   "name": "conda-env-programacion2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
